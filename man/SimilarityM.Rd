% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SimilarityM.R
\name{SimilarityM}
\alias{SimilarityM}
\title{Compute the similarity matrix}
\usage{
SimilarityM(lambda = 0.5, data, comps_knn = NULL, k_neighbors = NULL,
  use_umap_indices = FALSE, pre_embed_method = "umap", ...)
}
\arguments{
\item{lambda}{the balance term between the rank of Z and the error, default is 0.5}

\item{data}{the expression data, where each column is treated as a normalized vector}

\item{comps_knn}{number of components to use for knn, overrides eigengap-based inference}

\item{k_neighbors}{the number of neighbors for knn, overrides zero eigenvalue-based inference}

\item{use_umap_indices}{use the knn indices computed during umap embedding to impose sparsity on L2R2, instead of recomputing based on the layout.}

\item{pre_embed_method}{how the initial non-linear embedding is performed, default is 'umap'}

\item{...}{extra arguments passed to umap or Rtsne}
}
\value{
a list containing 
    \item{W}{the similarity matrix}
    \item{E}{the error of the ADMM step}
    \item{nl_embedding}{the KNN sparsity constraint is based on this embedding}
}
\description{
Computes low dim embedding, constructs KNN graph on the embedding -> unweighted adjacency
Calls manifold learning algorithm which uses the normalized sample vectors and the
unweighted adjacency matrix to compute a low rank approximation of the data.
}
